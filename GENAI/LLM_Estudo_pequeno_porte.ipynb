{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7exEaZkNuFOV"
   },
   "source": [
    "# **Pequena LLM usando LSTM | Projeto geração de texto usando LSTMs**\n",
    "\n",
    "Esse projeto é um modelo de Linguagem de Grande (LLM) de pequena escala usando uma rede neural LSTM (Long Short-Term Memory). Este modelo é capaz de gerar texto sequencial com base em padrões aprendidos a partir de dados textuais de entrada. Aqui está um resumo do que o modelo faz: <br>\n",
    "\n",
    "**Pré-processamento de Texto**\n",
    "\n",
    "O texto é limpo e tokenizado para prepará-lo para o treinamento.\n",
    "Sequências de tokens são geradas para alimentar o modelo.\n",
    "\n",
    "\n",
    "<br>**Construção do Modelo**:\n",
    "\n",
    "O modelo é construído usando a biblioteca Keras com uma camada de Embedding seguida por uma camada LSTM para capturar dependências sequenciais.\n",
    "Dropout é usado para regularização e uma camada Dense final com ativação softmax gera a previsão da próxima palavra.\n",
    "\n",
    "<br>**Geração de Texto:**\n",
    "\n",
    "Uma função para gerar texto com base em um prompt inicial, onde o modelo prevê palavras sucessivas para formar novas sequências de texto.\n",
    "Este projeto é um ponto de partida para explorar modelos de linguagem menores e pode ser expandido com mais dados e ajustes para alcançar desempenho superior em tarefas de geração de texto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQHyLk4luElX"
   },
   "outputs": [],
   "source": [
    "# Módulos Keras para construir a LSTM\n",
    "import keras.utils as ku\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Frameoworks de manipualçai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os\n",
    "import warnings\n",
    "\n",
    "# Configura uma semente para gerar números aleatórios de forma reprodutível\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "# Controlar a exibição de avisos\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYGNMXwduepQ"
   },
   "source": [
    "1. **keras.utils** <br>\n",
    "Este módulo fornece várias funções utilitárias para facilitar a manipulação de dados e o pré-processamento necessário para o treinamento de redes neurais.\n",
    "\n",
    "\n",
    "2. **keras.preprocessing.sequence.pad_sequences** <br>\n",
    "pad_sequences é uma função útil para garantir que todas as sequências de entrada tenham o mesmo comprimento, preenchendo com zeros (ou outro valor) conforme necessário.\n",
    "\n",
    "\n",
    "3. **keras.layers.Embedding** <br>\n",
    "A camada de Embedding é crucial para converter tokens de palavras em vetores densos de dimensão fixa, o que é necessário para a entrada na LSTM.\n",
    "\n",
    "\n",
    "4. **keras.layers.LSTM** <br>\n",
    "A camada LSTM é o coração do seu modelo sequencial, permitindo que ele aprenda dependências temporais em dados sequenciais.\n",
    "\n",
    "\n",
    "5. **keras.layers.Dense** <br>\n",
    "A camada Dense é uma camada totalmente conectada que geralmente é usada para a saída do modelo, onde cada unidade é conectada a todas as unidades na camada anterior.\n",
    "\n",
    "\n",
    "6. **keras.layers.Dropout** <br>\n",
    "A camada Dropout é usada para prevenir overfitting durante o treinamento, desligando aleatoriamente uma fração das unidades durante a etapa de treinamento.\n",
    "\n",
    "\n",
    "7. **keras.preprocessing.text.Tokenizer** <br>\n",
    "O Tokenizer é usado para converter texto bruto em tokens, que podem então ser convertidos em sequências de inteiros.\n",
    "\n",
    "\n",
    "8. **keras.callbacks.EarlyStopping** <br>\n",
    "EarlyStopping é uma técnica de regularização que interrompe o treinamento do modelo quando a métrica monitorada (como a perda de validação) para de melhorar, prevenindo overfitting e economizando tempo de treinamento.\n",
    "\n",
    "\n",
    "9. **keras.models.Sequential** <br>\n",
    "O Sequential é um contêiner linear para empilhar camadas do modelo de forma sequencial, do início ao fim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NgMk0c2x4NH"
   },
   "source": [
    "### **Leitura dos dados**\n",
    "Carregar o conjunto de dados de manchetes de notícias.<br>\n",
    "Para os dados usei um conjunto de dados de notícias do New Yor Times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FlYuZbBuK-W",
    "outputId": "894d506b-fbce-49b8-bd89-c99904e5b240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localizadas 1250 manchetes\n"
     ]
    }
   ],
   "source": [
    "# Pasta com os arquivos\n",
    "Pasta = 'Artigos/'\n",
    "\n",
    "# Lista para armazenar os arquivos CSV\n",
    "Machetes_Localizadas = []\n",
    "\n",
    "# Loop para percorrer as pastas\n",
    "for nome_arquivo in os.listdir(Pasta):\n",
    "\n",
    "    # Verificar se o arquivo é um arquivo CSV\n",
    "    if 'Articles' in nome_arquivo:\n",
    "\n",
    "        # Ler o arquivo CSV\n",
    "        df_artigo = pd.read_csv(Pasta + nome_arquivo)\n",
    "\n",
    "        # Selecionando a coluna Machetes\n",
    "        Machetes_Localizadas.extend( list(df_artigo.headline.values) )\n",
    "        break\n",
    "\n",
    "# Retirando manchtes com o tema 'Unknown | Desconhecimento'\n",
    "Machetes_Localizadas = [Loop for Loop in Machetes_Localizadas if Loop != 'Unknown']\n",
    "\n",
    "print( f'Localizadas {len(Machetes_Localizadas)} manchetes' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "id": "yl_DDFJA9Mot",
    "outputId": "6dc70918-dfa7-4f83-ab57-e335cf38a1b9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_artigo\",\n  \"rows\": 1385,\n  \"fields\": [\n    {\n      \"column\": \"articleID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1385,\n        \"samples\": [\n          \"5ab96d8c47de81a9012178f2\",\n          \"5a9ebea6410cf7000162f1ad\",\n          \"5a9d56d947de81a90120a42c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"byline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 783,\n        \"samples\": [\n          \"By MARK LANDLER and JIM TANKERSLEY\",\n          \"By TAMMY La GORCE\",\n          \"By JAN RANSOM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"documentType\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"article\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"headline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1246,\n        \"samples\": [\n          \"Celebrity Challenge to Cuomo  Cites Inequality and the M.T.A.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1237,\n        \"samples\": [\n          \"['United States Politics and Government', 'China', 'International Trade and World Market', 'Trump, Donald J', 'Lighthizer, Robert E', 'Customs (Tariff)']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"multimedia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"newDesk\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 38,\n        \"samples\": [\n          \"Investigative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"printPage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 0,\n        \"max\": 115,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pubDate\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1307,\n        \"samples\": [\n          \"2018-03-28 15:18:35\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sectionName\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 38,\n        \"samples\": [\n          \"Energy & Environment \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snippet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1369,\n        \"samples\": [\n          \"As readers turn the page, the portraits undergo an \\u2018interactive\\u2019 transformation that represents the mission of the section.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"International New York Times\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"typeOfMaterial\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Editorial\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"webURL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1385,\n        \"samples\": [\n          \"https://www.nytimes.com/2018/03/26/world/europe/russia-poisoning-expulsions.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"articleWordCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 785,\n        \"min\": 55,\n        \"max\": 11491,\n        \"num_unique_values\": 944,\n        \"samples\": [\n          970\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_artigo"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-33329613-ac90-4c94-8901-6c8602322b0d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "      <th>articleWordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a974697410cf7000162e8a4</td>\n",
       "      <td>By BINYAMIN APPELBAUM</td>\n",
       "      <td>article</td>\n",
       "      <td>Virtual Coins, Real Resources</td>\n",
       "      <td>['Bitcoin (Currency)', 'Electric Light and Pow...</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-01 00:17:22</td>\n",
       "      <td>Economy</td>\n",
       "      <td>America has a productivity problem. One explan...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/02/28/business/ec...</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a974be7410cf7000162e8af</td>\n",
       "      <td>By HELENE COOPER and ERIC SCHMITT</td>\n",
       "      <td>article</td>\n",
       "      <td>U.S. Advances Military Plans for North Korea</td>\n",
       "      <td>['United States Defense and Military Forces', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Washington</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-03-01 00:40:01</td>\n",
       "      <td>Asia Pacific</td>\n",
       "      <td>The American military is looking at everything...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/02/28/world/asia/...</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a9752a2410cf7000162e8ba</td>\n",
       "      <td>By THE EDITORIAL BOARD</td>\n",
       "      <td>article</td>\n",
       "      <td>Mr. Trump and the ‘Very Bad Judge’</td>\n",
       "      <td>['Trump, Donald J', 'Curiel, Gonzalo P', 'Unit...</td>\n",
       "      <td>1</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>26</td>\n",
       "      <td>2018-03-01 01:08:46</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Can you guess which man is the model public se...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>https://www.nytimes.com/2018/02/28/opinion/tru...</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a975310410cf7000162e8bd</td>\n",
       "      <td>By JAVIER C. HERNÁNDEZ</td>\n",
       "      <td>article</td>\n",
       "      <td>To Erase Dissent, China Bans Pooh Bear and ‘N’</td>\n",
       "      <td>['China', 'Xi Jinping', 'Term Limits (Politica...</td>\n",
       "      <td>1</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-01 01:10:35</td>\n",
       "      <td>Asia Pacific</td>\n",
       "      <td>Censors swung into action after Mr. Xi’s bid t...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/02/28/world/asia/...</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a975406410cf7000162e8c3</td>\n",
       "      <td>By JESSE DRUCKER, KATE KELLY and BEN PROTESS</td>\n",
       "      <td>article</td>\n",
       "      <td>Loans Flowed to Kushner Cos. After Visits to t...</td>\n",
       "      <td>['Kushner, Jared', 'Kushner Cos', 'United Stat...</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-01 01:14:41</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Apollo, the private equity firm, and Citigroup...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/02/28/business/ja...</td>\n",
       "      <td>1566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33329613-ac90-4c94-8901-6c8602322b0d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-33329613-ac90-4c94-8901-6c8602322b0d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-33329613-ac90-4c94-8901-6c8602322b0d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-3a72d8c4-0f0f-47d7-b4df-6497bac91fb7\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a72d8c4-0f0f-47d7-b4df-6497bac91fb7')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-3a72d8c4-0f0f-47d7-b4df-6497bac91fb7 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                  articleID                                        byline  \\\n",
       "0  5a974697410cf7000162e8a4                         By BINYAMIN APPELBAUM   \n",
       "1  5a974be7410cf7000162e8af             By HELENE COOPER and ERIC SCHMITT   \n",
       "2  5a9752a2410cf7000162e8ba                        By THE EDITORIAL BOARD   \n",
       "3  5a975310410cf7000162e8bd                        By JAVIER C. HERNÁNDEZ   \n",
       "4  5a975406410cf7000162e8c3  By JESSE DRUCKER, KATE KELLY and BEN PROTESS   \n",
       "\n",
       "  documentType                                           headline  \\\n",
       "0      article                      Virtual Coins, Real Resources   \n",
       "1      article       U.S. Advances Military Plans for North Korea   \n",
       "2      article                 Mr. Trump and the ‘Very Bad Judge’   \n",
       "3      article     To Erase Dissent, China Bans Pooh Bear and ‘N’   \n",
       "4      article  Loans Flowed to Kushner Cos. After Visits to t...   \n",
       "\n",
       "                                            keywords  multimedia     newDesk  \\\n",
       "0  ['Bitcoin (Currency)', 'Electric Light and Pow...           1    Business   \n",
       "1  ['United States Defense and Military Forces', ...           1  Washington   \n",
       "2  ['Trump, Donald J', 'Curiel, Gonzalo P', 'Unit...           1   Editorial   \n",
       "3  ['China', 'Xi Jinping', 'Term Limits (Politica...           1     Foreign   \n",
       "4  ['Kushner, Jared', 'Kushner Cos', 'United Stat...           1    Business   \n",
       "\n",
       "   printPage              pubDate   sectionName  \\\n",
       "0          1  2018-03-01 00:17:22       Economy   \n",
       "1         11  2018-03-01 00:40:01  Asia Pacific   \n",
       "2         26  2018-03-01 01:08:46       Unknown   \n",
       "3          1  2018-03-01 01:10:35  Asia Pacific   \n",
       "4          1  2018-03-01 01:14:41       Unknown   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  America has a productivity problem. One explan...  The New York Times   \n",
       "1  The American military is looking at everything...  The New York Times   \n",
       "2  Can you guess which man is the model public se...  The New York Times   \n",
       "3  Censors swung into action after Mr. Xi’s bid t...  The New York Times   \n",
       "4  Apollo, the private equity firm, and Citigroup...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \\\n",
       "0           News  https://www.nytimes.com/2018/02/28/business/ec...   \n",
       "1           News  https://www.nytimes.com/2018/02/28/world/asia/...   \n",
       "2      Editorial  https://www.nytimes.com/2018/02/28/opinion/tru...   \n",
       "3           News  https://www.nytimes.com/2018/02/28/world/asia/...   \n",
       "4           News  https://www.nytimes.com/2018/02/28/business/ja...   \n",
       "\n",
       "   articleWordCount  \n",
       "0              1207  \n",
       "1              1215  \n",
       "2              1043  \n",
       "3              1315  \n",
       "4              1566  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DF dos artigos\n",
    "df_artigo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dC095XcFzI3R"
   },
   "source": [
    "### **Preparação do texto**\n",
    "Na etapa de preparação do conjunto de dados, primeiro realizaremos a limpeza do texto dos dados, que inclui a remoção de pontuações e letras minúsculas em todas as palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXtYr0fYxFkH",
    "outputId": "b5cd512d-a393-4210-e18d-b450f1cc2e39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virtual coins real resources',\n",
       " 'us advances military plans for north korea',\n",
       " 'mr trump and the very bad judge',\n",
       " 'to erase dissent china bans pooh bear and n',\n",
       " 'loans flowed to kushner cos after visits to the white house']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Limpeza_Texto(Texto):\n",
    "  '''\n",
    "  Função limpar o texto\n",
    "  - Remove a pontuação do texto\n",
    "  - Converte o texto para minúsculas\n",
    "  - Remove caracteres não ASCII\n",
    "  '''\n",
    "  # Remoção de Pontuação e Conversão para Minúsculas\n",
    "  Texto = ''.join( Loop for Loop in Texto if Loop not in string.punctuation).lower()\n",
    "\n",
    "  # Codificação UTF-8 e Decodificação ASCII\n",
    "  Texto = Texto.encode('utf8').decode('ascii','ignore')\n",
    "\n",
    "  return Texto\n",
    "\n",
    "# Aplicando a função em uma lista\n",
    "Lista_Textos = [ Limpeza_Texto(Loop) for Loop in Machetes_Localizadas ]\n",
    "Lista_Textos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cGlr92Pg01H8",
    "outputId": "abe00907-9033-45f2-8385-4af615b014ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Lista_Textos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pr2w1R5rCGce"
   },
   "source": [
    "### **Gerando Sequência de Tokens N-gram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq0Rae2rEVtL"
   },
   "source": [
    "Gerar sequências de tokens N-gram é um processo utilizado em processamento de linguagem natural para representar texto sequencialmente. Um N-grama refere-se a uma sequência contígua de N itens, que no contexto de processamento de texto são tokens individuais (palavras ou caracteres).\n",
    "\n",
    "Por exemplo, em um texto \"O gato pulou\", os 2-gramas seriam \"O gato\", \"gato pulou\", e assim por diante. Isso captura a ordem das palavras e pode ser usado para entender padrões de linguagem, como coocorrências e dependências locais entre tokens adjacentes.\n",
    "\n",
    "Esse método é amplamente utilizado em tarefas como modelagem de linguagem, tradução automática e análise de sentimento, ajudando a capturar informações contextuais importantes para análise textual.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "VFNnb1GSyoLQ",
    "outputId": "77b52dbe-22c9-400b-c99e-d56f6343f7e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1119, 1120],\n",
       " [1119, 1120, 116],\n",
       " [1119, 1120, 116, 1121],\n",
       " [31, 1122],\n",
       " [31, 1122, 589],\n",
       " [31, 1122, 589, 392],\n",
       " [31, 1122, 589, 392, 7],\n",
       " [31, 1122, 589, 392, 7, 61],\n",
       " [31, 1122, 589, 392, 7, 61, 70],\n",
       " [117, 10],\n",
       " [117, 10, 6],\n",
       " [117, 10, 6, 1]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializa um objeto Tokenizer para a tokenização do texto\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "def obter_sequencia_tokens(corpus):\n",
    "    '''\n",
    "    Esta função realiza a tokenização de um corpus de texto e gera sequências de tokens (n-gramas).\n",
    "\n",
    "    Passos que a função executa:\n",
    "    - Ajusta um objeto Tokenizer aos textos do corpus para construir um índice de palavras.\n",
    "    - Converte cada linha do corpus em uma lista de tokens, onde cada palavra é substituída pelo seu índice correspondente.\n",
    "    - Gera todas as subsequências possíveis (n-gramas) para cada linha do corpus.\n",
    "    - Retorna uma lista de todas as subsequências de tokens e o número total de palavras únicas no corpus.\n",
    "\n",
    "    Parâmetros:\n",
    "    - corpus: uma lista de strings, onde cada string é uma linha de texto do corpus.\n",
    "\n",
    "    Retorna:\n",
    "    - input_sequences: uma lista de listas, onde cada sublista é uma sequência de tokens.\n",
    "    - total_words: um inteiro representando o número total de palavras únicas no corpus mais um.\n",
    "    '''\n",
    "\n",
    "    # Ajusta o Tokenizer aos textos do corpus, construindo o índice de palavras\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    # Calcula o número total de palavras no índice + 1 (para considerar o índice 0)\n",
    "    total_palavras = len(tokenizer.word_index) + 1\n",
    "\n",
    "    ## convert data to sequence of tokens\n",
    "    # Inicializa uma lista para armazenar as sequências de tokens\n",
    "    entrada_sequencia = []\n",
    "\n",
    "    # Itera sobre cada linha no corpus\n",
    "    for linha in corpus:\n",
    "\n",
    "        # Converte a linha em uma sequência de tokens\n",
    "        token_list = tokenizer.texts_to_sequences( [linha] )[0]\n",
    "\n",
    "        # Cria n-gramas a partir da sequência de tokens\n",
    "        for Loop in range(1, len(token_list)):\n",
    "\n",
    "          # Gera um n-grama que inclui do primeiro token até o token Loop+1\n",
    "          n_gram_sequence = token_list[:Loop+1]\n",
    "\n",
    "          # Adiciona a sequência de tokens ao conjunto de entrada\n",
    "          entrada_sequencia.append(n_gram_sequence)\n",
    "\n",
    "    # Retorna as sequências de entrada e o número total de palavras\n",
    "    return entrada_sequencia, total_palavras\n",
    "\n",
    "# Chama a função e armazena as sequências de entrada e o total de palavras\n",
    "sequencia_entrada, total_palavras = obter_sequencia_tokens(Lista_Textos)\n",
    "\n",
    "# Exibe as primeiras 10 sequências de entrada\n",
    "sequencia_entrada[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0UEGPM8CQJm"
   },
   "source": [
    "### **Preenchendo as sequências**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99kdyPCJEd9a"
   },
   "source": [
    "Preencher as sequências refere-se ao processo de ajustar o comprimento das sequências de dados para que todas tenham o mesmo tamanho. Isso é importante em modelos de aprendizado profundo, como redes neurais, onde os dados de entrada devem ter dimensões uniformes para serem processados eficientemente.\n",
    "\n",
    "Geralmente, as sequências são preenchidas com tokens especiais (como zeros) antes ou depois dos dados reais, de modo que todas tenham o mesmo comprimento máximo. Isso facilita o processamento em lotes (batches) e otimiza o desempenho durante o treinamento e a inferência dos modelos.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ujRzV9cX04v1"
   },
   "outputs": [],
   "source": [
    "def gerar_sequencia_preenchida(sequencia_entrada):\n",
    "    '''\n",
    "    Esta função padroniza as sequências de entrada para que todas tenham o mesmo comprimento,\n",
    "    e então as divide em preditores e rótulos para treinamento de um modelo.\n",
    "\n",
    "    Passos que a função executa:\n",
    "    - Encontra o comprimento máximo das sequências de entrada.\n",
    "    - Padroniza (preenche) todas as sequências de entrada para que tenham o mesmo comprimento.\n",
    "    - Divide as sequências de entrada em preditores (todos os tokens exceto o último) e rótulos (o último token).\n",
    "    - Converte os rótulos em uma matriz categórica (one-hot encoding).\n",
    "\n",
    "    Parâmetros:\n",
    "    - sequencia_entrada: uma lista de listas, onde cada sublista é uma sequência de tokens.\n",
    "\n",
    "    Retorna:\n",
    "    - predictors: uma matriz onde cada linha é uma sequência de tokens usada como entrada para o modelo.\n",
    "    - label: uma matriz categórica onde cada linha é o rótulo correspondente à sequência de entrada.\n",
    "    - max_sequence_len: um inteiro representando o comprimento máximo das sequências padronizadas.\n",
    "    '''\n",
    "\n",
    "    # Encontra o comprimento máximo das sequências\n",
    "    comprimento_max_sequencia = max( [len(Loop) for Loop in sequencia_entrada] )\n",
    "\n",
    "    # Padroniza as sequências de entrada para que todas tenham o mesmo comprimento\n",
    "    sequencia_entrada = np.array(pad_sequences(sequencia_entrada, maxlen=comprimento_max_sequencia, padding='pre'))\n",
    "\n",
    "    # Divide as sequências de entrada em preditores e rótulos\n",
    "    preditores, label = sequencia_entrada[:,:-1], sequencia_entrada[:,-1]\n",
    "\n",
    "    # Converte os rótulos em uma matriz categórica (one-hot encoding)\n",
    "    label = ku.to_categorical(label, num_classes=total_palavras)\n",
    "\n",
    "    # Retorna os preditores, rótulos e o comprimento máximo das sequências\n",
    "    return preditores, label, comprimento_max_sequencia\n",
    "\n",
    "# Chama a função para gerar as sequências padronizadas, preditores e rótulos\n",
    "preditores, label, comprimento_max_sequencia = gerar_sequencia_preenchida(sequencia_entrada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjENkaaUCZ8R"
   },
   "source": [
    "### **Treinamento do Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "I7P8ICmr5GuC",
    "outputId": "81dd82b6-5683-4c63-b294-1fa563577b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 17, 10)            35820     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               44400     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3582)              361782    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 442002 (1.69 MB)\n",
      "Trainable params: 442002 (1.69 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def criacao_modelo(max_sequence_len, total_words):\n",
    "    '''\n",
    "    Esta função cria e compila um modelo de rede neural sequencial usando Keras, configurado para processamento de sequências de texto.\n",
    "\n",
    "    Passos que a função executa:\n",
    "    - Define o comprimento da entrada como o comprimento máximo da sequência menos 1.\n",
    "    - Inicializa um modelo sequencial.\n",
    "    - Adiciona uma camada de Embedding para transformar índices de palavras em vetores de dimensão 10.\n",
    "    - Adiciona uma camada LSTM com 100 unidades para capturar dependências sequenciais nos dados.\n",
    "    - Adiciona uma camada de Dropout com taxa de 0.1 para regularização.\n",
    "    - Adiciona uma camada densa (fully connected) com ativação 'softmax' para gerar uma distribuição de probabilidade sobre o vocabulário.\n",
    "    - Compila o modelo com a função de perda 'categorical_crossentropy' e o otimizador 'adam'.\n",
    "\n",
    "    Parâmetros:\n",
    "    - max_sequence_len: um inteiro representando o comprimento máximo das sequências de entrada.\n",
    "    - total_words: um inteiro representando o tamanho do vocabulário.\n",
    "\n",
    "    Retorna:\n",
    "    - model: o modelo de rede neural sequencial compilado.\n",
    "    '''\n",
    "\n",
    "    # Define o comprimento da entrada como o comprimento máximo da sequência menos 1\n",
    "    input_len = max_sequence_len - 1\n",
    "\n",
    "    # Inicializa um modelo sequencial\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adiciona a camada de Embedding de entrada\n",
    "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "\n",
    "    # Adiciona a camada oculta 1 - Camada LSTM\n",
    "    model.add(LSTM(100))\n",
    "\n",
    "    # Adiciona a camada de Dropout para regularização\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Adiciona a camada de saída\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    # Compila o modelo com função de perda de entropia cruzada categórica e otimizador Adam\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    # Retorna o modelo compilado\n",
    "    return model\n",
    "\n",
    "# Cria o modelo usando o comprimento máximo da sequência e o número total de palavras\n",
    "model = criacao_modelo(comprimento_max_sequencia, total_palavras)\n",
    "\n",
    "# Exibe o resumo da arquitetura do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sM3l0fASCfBi"
   },
   "source": [
    "**DEMOROU EM TORNO DE 20 MINUTOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "51DRqE5T5JYJ",
    "outputId": "738303dc-78d8-4590-bf70-ff7aec040ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7bcb8b4ef9d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos treinar o modelo\n",
    "# Vai lavar louça, lavar carro, assistir série e depois volta :X\n",
    "model.fit( preditores, label, epochs=100, verbose=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cvfrMLnCrRS"
   },
   "source": [
    "### **Gerando o texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "gJ6bYyoo6xyU"
   },
   "outputs": [],
   "source": [
    "def generate_text(texto_inicial, proximas_palavras, model, sequencia_max):\n",
    "    \"\"\"\n",
    "    Esta função gera texto previsível com base em um texto inicial, um número especificado de palavras para gerar,\n",
    "    um modelo treinado e o comprimento máximo da sequência de entrada.\n",
    "\n",
    "    Parâmetros:\n",
    "    - texto_inicial: string, o texto inicial a partir do qual o novo texto será gerado.\n",
    "    - proximas_palavras: inteiro, o número de palavras a serem geradas.\n",
    "    - model: o modelo de rede neural treinado usado para prever as próximas palavras.\n",
    "    - sequencia_max: inteiro, o comprimento máximo das sequências usadas durante o treinamento do modelo.\n",
    "\n",
    "    Retorna:\n",
    "    - Uma string contendo o texto inicial seguido pelas novas palavras geradas, com a primeira letra de cada palavra em maiúscula.\n",
    "    \"\"\"\n",
    "\n",
    "    for Loop in range(proximas_palavras):\n",
    "\n",
    "        # Converte o texto inicial em uma lista de tokens\n",
    "        lista_token = tokenizer.texts_to_sequences([texto_inicial])[0]\n",
    "\n",
    "        # Padroniza a lista de tokens para ter o comprimento máximo da sequência menos 1\n",
    "        lista_token = pad_sequences([lista_token], maxlen=sequencia_max-1, padding='pre')\n",
    "\n",
    "        # Usa o modelo para prever a próxima palavra na sequência\n",
    "        predicted_probs = model.predict(lista_token, verbose=0)\n",
    "        predicted = np.argmax(predicted_probs, axis=-1)[0]\n",
    "\n",
    "        # Inicializa a variável para armazenar a palavra prevista\n",
    "        palavra_saida = \"\"\n",
    "\n",
    "        # Encontra a palavra correspondente ao índice previsto\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                palavra_saida = word\n",
    "                break\n",
    "\n",
    "        # Adiciona a palavra prevista ao texto inicial\n",
    "        texto_inicial += \" \" + palavra_saida\n",
    "\n",
    "    # Retorna o texto gerado com a primeira letra de cada palavra em maiúscula\n",
    "    return texto_inicial.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-_7F9XOCw0R"
   },
   "source": [
    "### **Demostrando | Prompt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IjIKXqmFHpf"
   },
   "source": [
    "Lembrando que os dados são de nóticias do New York times meados 2018.\n",
    "\n",
    "Naquele momento havia muita citação ao Trump nos artigos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "3yaWPQ2V-e0w"
   },
   "outputs": [],
   "source": [
    "def demonstrar_geracao_texto(prompt, quantidade_palavras, model, max_sequence_len):\n",
    "    \"\"\"\n",
    "    Esta função demonstra a geração de texto usando um modelo treinado.\n",
    "\n",
    "    Parâmetros:\n",
    "    - prompt: string, o texto inicial a partir do qual o novo texto será gerado.\n",
    "    - quantidade_palavras: inteiro, o número de palavras a serem geradas.\n",
    "    - model: o modelo de rede neural treinado usado para prever as próximas palavras.\n",
    "    - max_sequence_len: inteiro, o comprimento máximo das sequências usadas durante o treinamento do modelo.\n",
    "\n",
    "    Retorna:\n",
    "    - O texto gerado com a primeira letra de cada palavra em maiúscula.\n",
    "    \"\"\"\n",
    "    # Gera o texto usando o modelo\n",
    "    texto_gerado = generate_text(prompt, quantidade_palavras, model, max_sequence_len)\n",
    "\n",
    "    # Exibe o texto gerado\n",
    "    print(\"Texto Inicial: \", prompt)\n",
    "    print(\"Quantidade de Palavras Geradas: \", quantidade_palavras)\n",
    "    print(\"Texto Gerado: \", texto_gerado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "JuxopPPkAFqj",
    "outputId": "80562543-0037-43f3-f442-a185948af806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto Inicial:  president trump\n",
      "Quantidade de Palavras Geradas:  10\n",
      "Texto Gerado:  President Trump Tv Commentator As Amazon The Suv Is Be A Census\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "Prompt = 'president trump'\n",
    "Quantidade_Palavras = 10\n",
    "\n",
    "demonstrar_geracao_texto( Prompt, Quantidade_Palavras, model, comprimento_max_sequencia )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "bem238q2A3iL",
    "outputId": "d8baf34b-a661-408f-eb9f-c26278b75c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto Inicial:  New York\n",
      "Quantidade de Palavras Geradas:  9\n",
      "Texto Gerado:  New York Forgets Its Juvenile Lifers From The Census Treatment Thrills\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "Prompt = 'New York'\n",
    "Quantidade_Palavras = 9\n",
    "\n",
    "demonstrar_geracao_texto( Prompt, Quantidade_Palavras, model, comprimento_max_sequencia )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "961kruJbEuRr",
    "outputId": "b443d8f7-9f80-46fc-abd1-554f23ebaec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto Inicial:  United States\n",
      "Quantidade de Palavras Geradas:  12\n",
      "Texto Gerado:  United States About Trump Tied To The White House Built In The 80S Is\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "Prompt = 'United States'\n",
    "Quantidade_Palavras = 12\n",
    "\n",
    "demonstrar_geracao_texto( Prompt, Quantidade_Palavras, model, comprimento_max_sequencia )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fFr3xwME6Ji"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
